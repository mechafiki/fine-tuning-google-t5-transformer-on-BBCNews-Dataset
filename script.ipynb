{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np                                                                                    # Algèbre linéaire\n",
    "import torch                                                                                          # pytorch\n",
    "from sklearn.model_selection import train_test_split                                                  # division train/test\n",
    "import pandas as pd                                                                                   # traitement de données\n",
    "from datasets import load_dataset                                                                     # chargement de dataset\n",
    "import glob                                                                                           # glob pour les fichiers\n",
    "import os                                                                                             # os pour les fichiers\n",
    "import re                                                                                             # regex\n",
    "import nltk\n",
    "import torch\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "from datasets import load_metric\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer,PreTrainedTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint ='t5-small' # \n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "assert isinstance(tokenizer, PreTrainedTokenizerFast)\n",
    "\n",
    "pad_on_right = tokenizer.padding_side == \"right\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):                                                              # fonction pour lire les fichiers\n",
    "    data = []\n",
    "    for topic in os.listdir(path):\n",
    "        for file in os.listdir(path + \"/\" + topic):                               # parcourir les fichiers par topic\n",
    "            with open(path + \"/\" + topic + \"/\" + file) as f:\n",
    "                data.append(f.read())\n",
    "    return data\n",
    "\n",
    "original_text = read_data(\"files/BBC News Summary/Summaries\")                      # lire le texte original\n",
    "summary_text = read_data(\"files/BBC News Summary/News Articles\")                   # lire le texte résumé\n",
    "\n",
    "df = pd.DataFrame({'original':original_text,'summary':summary_text})               # créer un dataframe avec les deux colonnes\n",
    "\n",
    "df.to_csv('files/summary.csv', index=False)                                        # sauvegarder le dataframe en csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-bc168876467c789e\n",
      "Found cached dataset csv (C:/Users/moham/.cache/huggingface/datasets/csv/default-bc168876467c789e/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv', data_files='files/summary.csv', split='train')       # charger le dataset\n",
    "dataset = dataset.train_test_split(test_size=0.1)                                  # diviser le dataset en train/test\n",
    "train_dataset = dataset['train']                                                   # train dataset\n",
    "test_dataset = dataset['test'] \n",
    "dataset = train_dataset.train_test_split(test_size=0.1)                                  \n",
    "train_dataset = dataset['train']\n",
    "val_dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 150\n",
    "max_target_length = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs = ['summarize:' + doc for doc in examples[\"original\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True,padding='max_length')\n",
    "\n",
    "    # Setup the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples[\"summary\"], max_length=max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?ba/s]C:\\Users\\moham\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\tokenization_utils_base.py:3578: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.50s/ba]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.36ba/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_train = train_dataset.map(preprocess_function, batched=True)\n",
    "tokenized_valid = val_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 242M/242M [00:21<00:00, 11.4MB/s] \n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "batch_size = 16\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    \n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    # Extract a few results\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "    \n",
    "    # Add mean generated length\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    \n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1417"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] using cpu device\n"
     ]
    }
   ],
   "source": [
    "# determine the device we will be using for training\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"[INFO] using {} device\".format(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_DISABLED=True\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_DISABLED=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "The following columns in the training set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: original, summary. If original, summary are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "C:\\Users\\moham\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1801\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 565\n",
      "  Number of trainable parameters = 60506624\n",
      "Trainer is attempting to log a value of \"{'summarization': {'early_stopping': True, 'length_penalty': 2.0, 'max_length': 200, 'min_length': 30, 'no_repeat_ngram_size': 3, 'num_beams': 4, 'prefix': 'summarize: '}, 'translation_en_to_de': {'early_stopping': True, 'max_length': 300, 'num_beams': 4, 'prefix': 'translate English to German: '}, 'translation_en_to_fr': {'early_stopping': True, 'max_length': 300, 'num_beams': 4, 'prefix': 'translate English to French: '}, 'translation_en_to_ro': {'early_stopping': True, 'max_length': 300, 'num_beams': 4, 'prefix': 'translate English to Romanian: '}}\" for key \"task_specific_params\" as a parameter. MLflow's log_param() only accepts values no longer than 250 characters so we dropped this attribute. You can use `MLFLOW_FLATTEN_PARAMS` environment variable to flatten the parameters and avoid this message.\n",
      "  0%|          | 0/565 [00:00<?, ?it/s]You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      " 20%|██        | 113/565 [27:48<1:17:39, 10.31s/it]The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: original, summary. If original, summary are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 201\n",
      "  Batch size = 16\n",
      "                                                   \n",
      " 20%|██        | 113/565 [29:15<1:17:39, 10.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.488041877746582, 'eval_rouge1': 26.2538, 'eval_rouge2': 17.4694, 'eval_rougeL': 23.2642, 'eval_rougeLsum': 24.6511, 'eval_gen_len': 19.0, 'eval_runtime': 86.56, 'eval_samples_per_second': 2.322, 'eval_steps_per_second': 0.15, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 226/565 [52:57<59:24, 10.51s/it]  The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: original, summary. If original, summary are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 201\n",
      "  Batch size = 16\n",
      "                                                 \n",
      " 40%|████      | 226/565 [54:23<59:24, 10.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.3971829414367676, 'eval_rouge1': 26.4822, 'eval_rouge2': 18.5141, 'eval_rougeL': 23.884, 'eval_rougeLsum': 25.0978, 'eval_gen_len': 19.0, 'eval_runtime': 85.0513, 'eval_samples_per_second': 2.363, 'eval_steps_per_second': 0.153, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 339/565 [1:46:55<43:30, 11.55s/it]    The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: original, summary. If original, summary are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 201\n",
      "  Batch size = 16\n",
      "                                                   \n",
      " 60%|██████    | 339/565 [1:48:32<43:30, 11.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.359138250350952, 'eval_rouge1': 26.1709, 'eval_rouge2': 18.0859, 'eval_rougeL': 23.601, 'eval_rougeLsum': 24.7753, 'eval_gen_len': 19.0, 'eval_runtime': 96.8689, 'eval_samples_per_second': 2.075, 'eval_steps_per_second': 0.134, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 452/565 [2:13:29<22:06, 11.74s/it]  The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: original, summary. If original, summary are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 201\n",
      "  Batch size = 16\n",
      "                                                   \n",
      " 80%|████████  | 452/565 [2:15:04<22:06, 11.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.3406260013580322, 'eval_rouge1': 26.1378, 'eval_rouge2': 17.9916, 'eval_rougeL': 23.6076, 'eval_rougeLsum': 24.8443, 'eval_gen_len': 19.0, 'eval_runtime': 94.0975, 'eval_samples_per_second': 2.136, 'eval_steps_per_second': 0.138, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 500/565 [2:25:11<12:53, 11.90s/it]  Saving model checkpoint to t5-small-finetuned-newsarticles\\checkpoint-500\n",
      "Configuration saved in t5-small-finetuned-newsarticles\\checkpoint-500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.6348, 'learning_rate': 2.3008849557522127e-06, 'epoch': 4.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in t5-small-finetuned-newsarticles\\checkpoint-500\\pytorch_model.bin\n",
      "tokenizer config file saved in t5-small-finetuned-newsarticles\\checkpoint-500\\tokenizer_config.json\n",
      "Special tokens file saved in t5-small-finetuned-newsarticles\\checkpoint-500\\special_tokens_map.json\n",
      "Copy vocab file to t5-small-finetuned-newsarticles\\checkpoint-500\\spiece.model\n",
      "100%|██████████| 565/565 [2:37:28<00:00, 10.37s/it]The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: original, summary. If original, summary are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 201\n",
      "  Batch size = 16\n",
      "                                                   \n",
      "100%|██████████| 565/565 [2:38:50<00:00, 10.37s/it]\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "100%|██████████| 565/565 [2:38:50<00:00, 16.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.334956407546997, 'eval_rouge1': 26.1241, 'eval_rouge2': 18.0228, 'eval_rougeL': 23.5684, 'eval_rougeLsum': 24.8432, 'eval_gen_len': 19.0, 'eval_runtime': 81.1085, 'eval_samples_per_second': 2.478, 'eval_steps_per_second': 0.16, 'epoch': 5.0}\n",
      "{'train_runtime': 9530.7585, 'train_samples_per_second': 0.945, 'train_steps_per_second': 0.059, 'train_loss': 2.621244231367533, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=565, training_loss=2.621244231367533, metrics={'train_runtime': 9530.7585, 'train_samples_per_second': 0.945, 'train_steps_per_second': 0.059, 'train_loss': 2.621244231367533, 'epoch': 5.0})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    f\"{model_name}-finetuned-newsarticles\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=5,\n",
    "    predict_with_generate=True,\n",
    "    #fp16=True\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_valid,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "metric = load_metric(\"rouge\")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to files/t5-small-finetuned-newsarticles\n",
      "Configuration saved in files/t5-small-finetuned-newsarticles\\config.json\n",
      "Model weights saved in files/t5-small-finetuned-newsarticles\\pytorch_model.bin\n",
      "tokenizer config file saved in files/t5-small-finetuned-newsarticles\\tokenizer_config.json\n",
      "Special tokens file saved in files/t5-small-finetuned-newsarticles\\special_tokens_map.json\n",
      "Copy vocab file to files/t5-small-finetuned-newsarticles\\spiece.model\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "trainer.save_model(f\"files/{model_name}-finetuned-newsarticles\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?ba/s]C:\\Users\\moham\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\tokenization_utils_base.py:3578: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.09s/ba]\n",
      "The following columns in the test set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: original, summary. If original, summary are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 223\n",
      "  Batch size = 16\n",
      "100%|██████████| 14/14 [09:03<00:00, 38.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 2.333233594894409, 'test_rouge1': 45.4217, 'test_rouge2': 29.7591, 'test_rougeL': 35.8945, 'test_rougeLsum': 41.9565, 'test_gen_len': 97.9417, 'test_runtime': 588.5964, 'test_samples_per_second': 0.379, 'test_steps_per_second': 0.024}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_dataset = test_dataset.map(\n",
    "                preprocess_function,\n",
    "                batched=True)\n",
    "\n",
    "predict_results = trainer.predict(\n",
    "            test_dataset,max_length=128, num_beams=3)\n",
    "\n",
    "metrics = predict_results.metrics\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[    0, 26353,   739, ...,     0,     0,     0],\n",
       "       [    0,  1983,  9377, ...,     0,     0,     0],\n",
       "       [    0,    94,    56, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [    0, 13816,    65, ...,     0,     0,     0],\n",
       "       [    0,  1163,   243, ...,     0,     0,     0],\n",
       "       [    0,    37,   515, ...,     0,     0,     0]], dtype=int64), label_ids=array([[26353,   739, 17640, ...,     0,     0,     0],\n",
       "       [13824,   348,  9204, ...,     0,     0,     0],\n",
       "       [    3, 31105,  4420, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [13816,   177,   725, ...,     0,     0,     0],\n",
       "       [ 1163,    31,     7, ...,     0,     0,     0],\n",
       "       [ 2180,  1982,   144, ...,     0,     0,     0]], dtype=int64), metrics={'test_loss': 2.333233594894409, 'test_rouge1': 45.4217, 'test_rouge2': 29.7591, 'test_rougeL': 35.8945, 'test_rougeLsum': 41.9565, 'test_gen_len': 97.9417, 'test_runtime': 588.5964, 'test_samples_per_second': 0.379, 'test_steps_per_second': 0.024})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.predict_with_generate:\n",
    "    predictions = tokenizer.batch_decode(predict_results.predictions, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "    predictions = [pred.strip() for pred in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mandelson, a former Labour communications director, told BBC Radio 4\\'s Today programme: \"I understand why the Tories will be gunning for Alastair Campbell because they fear his campaigning skills. That charge was denied by Mr Mandelson, who said the Tories were afraid of Mr Campbell\\'s campaigning skills. The European commissioner and former Labour minister was speaking amid claims that Mr Campbell is part of a Labour \"dirty tricks\" campaign.',\n",
       " 'Actress Nicole Kidman has won a restraining order against two paparazzi photographers who she claims left her fearful of leaving her Sydney mansion. Nicole Kidman was prompted to take action following a reported high-speed car chase with members of the paparazzi in Sydney last weekend. Magistrate Lee Gilmore, who issued the restraining order at Waverley Local Court in Sydney, said she understood the photographers were entitled to earn a living but there had to be limits to their behaviour.']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mandelson warns BBC on Campbell\\n\\nThe BBC should steer away from \"demonising\" ex-Downing Street media chief Alastair Campbell, Peter Mandelson has said.\\n\\nThe European commissioner and former Labour minister was speaking amid claims that Mr Campbell is part of a Labour \"dirty tricks\" campaign. That charge was denied by Mr Mandelson, who said the Tories were afraid of Mr Campbell\\'s campaigning skills. He warned the BBC that attacking Mr Campbell had brought it trouble before. That was a reference to the Hutton inquiry following a BBC story claiming Downing Street \"sexed up\" Iraq\\'s weapons of mass destruction dossier.\\n\\nThe affair prompted the resignation of BBC chairman Gavyn Davies, director-general Greg Dyke and reporter Andrew Gilligan. Labour has attracted media criticism for using new freedom of information laws to dig up information about Tory leader Michael Howard\\'s past.\\n\\nMr Mandelson, a former Labour communications director, told BBC Radio 4\\'s Today programme: \"I understand why the Tories will be gunning for Alastair Campbell because they fear his campaigning skills. \"What I understand less is why the BBC should be joining with the Tories in driving that agenda. \"In my experience of these things, parties which shout about dirty tricks and the like tend to do so because they fear a direct hit in some vulnerable part of their political anatomy. \"I suggest the BBC concentrates on the issues and helps the public to understand the policies and the choices that are at stake in the election rather than engages in the process politics, the trivialisation of the campaign. \"I think the BBC would be much better advised to leave all this stuff well alone, concentrate on the issues as I say, not resume their demonisation of Alastair Campbell - we all know where that led before.\"\\n\\nMr Campbell is acting as an adviser for Labour, which denies engaging in personal campaigning. Conservative co-chairman Liam Fox said Mr Campbell\\'s return and Labour poster plans attacking Mr Howard - recently withdrawn from the party\\'s website - were a sign of \"abusive politics\". \"The government, despite the fact that they would say want to go forward, not back, seem intent on talking about history rather than their own record or even more importantly, about the future,\" he said on Sunday. Labour peer Baroness Kennedy, who is chairing the Power Inquiry into political disengagement, said people already thought politicians engaged in dirty tricks. \"This feeling of distrust is going to be enlarged if this campaigning on all sides is conducted in the way that it looks as if it just might,\" she said.\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset['summary'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a63501da4ff5345f792f8d85fdbe5e308a00ec1c83390f9577f8c8a1adb4af3a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
